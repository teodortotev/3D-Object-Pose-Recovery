\documentclass[main.tex]{subfiles}

\begin{document}
\section{Conclusion}
\subsection{Summary}
The project investigated a novel method for 3D pose recovery from monocular images. At the start it managed to generate ground truth part segmentation masks to be used in the following stages. This was done by splitting the provided CAD models into parts and rendering them to the 2D image plane through the provided viewpoint while simultaneously handling visibility and occlusions. Two fully convolutional networks (FCN and DLV3) were implemented to prove that neural networks are capable of learning how to produce the proposed part segmentation masks by analysing monocular images. These models showed that handling one object at a time improves the performance. Therefore, Faster R-CNN was employed to prove that it is possible to generate individual object detections and assign a corresponding CAD model to each of them. Consequently, the mask head of Mask R-CNN was modified to provide category independent part segmentations for each of the detected and classified object instances. Despite some improvements in the initial implementation, Mask R-CNN did not manage to reach the same levels of segmentation accuracy as FCN and DLV3. Therefore a combination of Mask R-CNN classified object detections and pre-trained FCN and DLV3 models was assembled. It accomplished the task to identify objects, assign corresponding CAD models and generate part segmentation masks that were deemed good enough for the pose estimation step. Finally, it was shown that key-point correspondences can be extracted from the part segmentation mask and the provided CAD model to define a PnP problem. Given a good initial guess and following a non-linear optimisation process, the viewpoint could be recovered.
\subsection{Future Work}
The limited time frame and resources meant that some of the ideas that came up during the work on this project could not be implemented and had to be left over for future projects. A brief summary of these will be provided here.\\
\indent To begin with, the project limited itself to the use of the "car" category. It is expected that the proposed method is applicable to other objects accompanied by the necessary ground truth information and more research could be done in this direction. It would be especially interesting to investigate the effect of symmetry on the segmentation and pose estimation processes. \\
\indent Additionally, the way object parts are defined in this project is unique. In future works their number, shape and semantic meaning can be varied. Moreover, the method can be tested on traditional object part segementation datasets if 3D models and viewpoint annotations are available.\\
\indent  When Mask R-CNN object detections were combined with FCN and DLV3, the models were pre-trained on whole images but considered individual object instances one at a time. Nevertheless, they showed a big improvement on the Mask R-CNN segmentation implementation. Therefore it should be possible to achieve even higher results by training both models to segment single objects in the first place.\\
\indent The modified mask head of Mask R-CNN managed to achieve a mIoU of just 34.01. Adding an additional mask for the background class raised slightly the quality of the predictions. Nevertheless, there is a lot of room for improvement. One potential step could be to modify the segmentation head to compute a loss function over a multi-class combined mask instead of n separate part masks. In addition, the depth maps generated during the rendering process could be included in the segmentation prediction.\\
\indent Finally, it was shown that the pose estimation step requires more key-points and a good initialisation. The Mask R-CNN framework can be extended to regress the anchor point positions provided by PASCAL3D+ and predict a stable initial point for the optimisation process.
\end{document}